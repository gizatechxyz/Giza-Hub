{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04w3OowXkaQh"
      },
      "source": [
        "# Using Quantization Aware Training in TensorFlow\n",
        "\n",
        "In this tutorial, we will discuss how to train a Quantization Aware Model using TensorFlow Model Optimization Toolkit (TF-MOT). Quantization Aware Training allows for reduced precision representations of weights and, optionally, activations for both storage and computation. This is particularly important for deploying models on hardware and platforms that don't support floating point operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sfci39Llvii",
        "outputId": "443499bf-8386-469a-8524-e8ad574944dd"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy tensorflow tensorflow_model_optimization matplotlib scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKiq8oKxklon"
      },
      "source": [
        "## Dataset Preparation\n",
        "We will use the popular MNIST dataset for this example. First, let's import the required libraries and load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4po2PWTAkWOR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXigQHM_k0ux"
      },
      "source": [
        "We have a total of 70,000 grayscale images, each with a dimension of 28 x 28 pixels. 60,000 images are for training and the remaining 10,000 are for testing.\n",
        "\n",
        "Now, we need to preprocess our data. We need to flatten our data and then normalize it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6AwxawnnkaA5"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Resizing function\n",
        "def resize_images(images):\n",
        "    return np.array([zoom(image, 0.5) for image in images])\n",
        "\n",
        "# Resize\n",
        "x_train = resize_images(x_train)\n",
        "x_test = resize_images(x_test)\n",
        "\n",
        "# Then reshape\n",
        "x_train = x_train.reshape(60000, 14*14)\n",
        "x_test = x_test.reshape(10000, 14*14)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize to range [0, 1]\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix3qnUgElDlB"
      },
      "source": [
        "## Model Definition and Training\n",
        "We will use a simple feedforward neural network (also known as Multi-layer Perceptron) for this task. Our model will have two hidden layers each with 256 neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7gilDCS6k9-u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(14*14,)), # Note the input shape should be 14*14 not 196\n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFUZZOudlQmP"
      },
      "source": [
        "Now let's train this model on our training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjkH102GlOd2",
        "outputId": "e872c568-6141-4c70-e070-bc552317f9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 1s 438us/step - loss: 0.8641 - accuracy: 0.7506 - val_loss: 0.3855 - val_accuracy: 0.8947\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 1s 391us/step - loss: 0.3713 - accuracy: 0.8953 - val_loss: 0.3160 - val_accuracy: 0.9096\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 1s 397us/step - loss: 0.3252 - accuracy: 0.9070 - val_loss: 0.2916 - val_accuracy: 0.9150\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 1s 389us/step - loss: 0.3041 - accuracy: 0.9122 - val_loss: 0.2758 - val_accuracy: 0.9207\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 1s 393us/step - loss: 0.2917 - accuracy: 0.9153 - val_loss: 0.2672 - val_accuracy: 0.9237\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 1s 386us/step - loss: 0.2827 - accuracy: 0.9187 - val_loss: 0.2599 - val_accuracy: 0.9258\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 1s 391us/step - loss: 0.2752 - accuracy: 0.9201 - val_loss: 0.2554 - val_accuracy: 0.9273\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 1s 390us/step - loss: 0.2685 - accuracy: 0.9218 - val_loss: 0.2525 - val_accuracy: 0.9282\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 1s 391us/step - loss: 0.2635 - accuracy: 0.9235 - val_loss: 0.2491 - val_accuracy: 0.9303\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 1s 392us/step - loss: 0.2593 - accuracy: 0.9256 - val_loss: 0.2467 - val_accuracy: 0.9302\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNRdKGpflar4"
      },
      "source": [
        "At this point, we have trained a regular model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bu55FCqlbj4"
      },
      "source": [
        "## Making the Model Quantization Aware\n",
        "Now, let's transform our model into a quantization aware model. We use the TensorFlow Model Optimization Toolkit for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZYo9vKlTHK",
        "outputId": "cbe04409-a767-44b9-db3c-be8b043d33cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLa  (None, 196)               3         \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrapp  (None, 10)                1975      \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWra  (None, 10)                115       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2093 (8.18 KB)\n",
            "Trainable params: 2080 (8.12 KB)\n",
            "Non-trainable params: 13 (52.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# Apply quantization to the layers\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for 'quantization aware'\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# 'quantize_model' requires a recompile\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYPUWWwTl_np"
      },
      "source": [
        "We have now created a new model, q_aware_model, which is a quantization aware version of our original model. Now we can train this model exactly like our original model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-t5MPhGlqoI",
        "outputId": "8d0d687f-0af2-44be-fad8-b9da86a20ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 1s 563us/step - loss: 0.2623 - accuracy: 0.9245 - val_loss: 0.2499 - val_accuracy: 0.9293\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 1s 503us/step - loss: 0.2539 - accuracy: 0.9260 - val_loss: 0.2473 - val_accuracy: 0.9296\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 1s 508us/step - loss: 0.2509 - accuracy: 0.9260 - val_loss: 0.2454 - val_accuracy: 0.9289\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 1s 520us/step - loss: 0.2484 - accuracy: 0.9278 - val_loss: 0.2444 - val_accuracy: 0.9293\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 1s 533us/step - loss: 0.2464 - accuracy: 0.9284 - val_loss: 0.2428 - val_accuracy: 0.9293\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 1s 516us/step - loss: 0.2440 - accuracy: 0.9282 - val_loss: 0.2409 - val_accuracy: 0.9309\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 1s 540us/step - loss: 0.2424 - accuracy: 0.9286 - val_loss: 0.2417 - val_accuracy: 0.9308\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 1s 517us/step - loss: 0.2409 - accuracy: 0.9294 - val_loss: 0.2391 - val_accuracy: 0.9304\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 1s 539us/step - loss: 0.2391 - accuracy: 0.9292 - val_loss: 0.2406 - val_accuracy: 0.9316\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 1s 518us/step - loss: 0.2380 - accuracy: 0.9294 - val_loss: 0.2428 - val_accuracy: 0.9304\n",
            "Test loss: 0.246782124042511\n",
            "Test accuracy: 0.928600013256073\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "history = q_aware_model.fit(x_train, y_train,\n",
        "                            epochs=epochs,\n",
        "                            validation_split=0.2)\n",
        "\n",
        "scores, acc = q_aware_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', scores)\n",
        "print('Test accuracy:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhbweTQEmWN-"
      },
      "source": [
        "## Converting to TFLite Format\n",
        "Now, we will convert our model to TFLite format, which is a format optimized for on-device machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOwZiCRWmHDT",
        "outputId": "da138eac-0897-4a9e-eff0-4840fc13d035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/s3/6c0gmns50x36dt6vvfhv6jhc0000gn/T/tmpxz_xbour/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/s3/6c0gmns50x36dt6vvfhv6jhc0000gn/T/tmpxz_xbour/assets\n",
            "/Users/raphaeldoukhan/Desktop/Cairo/Giza/orion_tutorials/.conda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "2023-06-08 15:36:18.041784: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2023-06-08 15:36:18.041798: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2023-06-08 15:36:18.042005: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/s3/6c0gmns50x36dt6vvfhv6jhc0000gn/T/tmpxz_xbour\n",
            "2023-06-08 15:36:18.042895: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2023-06-08 15:36:18.042899: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/s3/6c0gmns50x36dt6vvfhv6jhc0000gn/T/tmpxz_xbour\n",
            "2023-06-08 15:36:18.045027: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2023-06-08 15:36:18.046011: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2023-06-08 15:36:18.076064: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/s3/6c0gmns50x36dt6vvfhv6jhc0000gn/T/tmpxz_xbour\n",
            "2023-06-08 15:36:18.085919: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 43917 microseconds.\n",
            "2023-06-08 15:36:18.095503: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4312"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "\n",
        "# Indicate that you want to perform default optimizations,\n",
        "# which include quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Define a generator function that provides your test data's numpy arrays\n",
        "def representative_data_gen():\n",
        "  for i in range(500):\n",
        "    yield [x_test[i:i+1]]\n",
        "\n",
        "# Use the generator function to guide the quantization process\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Set the input and output tensors to int8\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"q_aware_model.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxGWitSs3MAH"
      },
      "source": [
        "## Testing the Quantized Model\n",
        "Now that we have trained a quantization-aware model and converted it to the TFLite format, we can now perform inference using the TensorFlow Lite interpreter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sXEM3WEv3SSt"
      },
      "outputs": [],
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qbfjJFa3Zy7"
      },
      "source": [
        "We first load the TFLite model and allocate the required tensors. The Interpreter class provides methods for loading a model and running inferences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "T7r8JFTC3Xxe"
      },
      "outputs": [],
      "source": [
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6WRo1L3dZp"
      },
      "source": [
        "Next, we get the details of the input and output tensors. Each tensor in a TensorFlow Lite model has a name, index, shape, data type, and quantization parameters. These can be accessed via the input_details and output_details methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-1yOJjl83b9i"
      },
      "outputs": [],
      "source": [
        "# Normalize the input value to int8\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(x_test[0:1], dtype=np.int8)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Perform the inference\n",
        "interpreter.invoke()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofFMDXq13ix7"
      },
      "source": [
        "Before performing the inference, we need to normalize the input to match the data type of our model's input tensor, which in our case is int8. Then, we use the set_tensor method to provide the input data to the model. We perform the inference using the invoke method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtfTBPCl3iKm",
        "outputId": "a16ac7eb-d50c-44c7-8a51-0924ebe41473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-128 -128   -6   -6 -128 -116 -128 -128 -128 -128]]\n"
          ]
        }
      ],
      "source": [
        "# Get the result\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge-Y3K1J3oWs"
      },
      "source": [
        "After the inference, we get the output data from the model's output tensor.\n",
        "\n",
        "Now, we are going to run the inference for the entire test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B5fDA1Vt3num"
      },
      "outputs": [],
      "source": [
        "(_, _), (x_test_image, y_test_label) = mnist.load_data()\n",
        "\n",
        "# Resize and Normalize x_test_image to int8\n",
        "x_test_image = resize_images(x_test_image)\n",
        "x_test_image_norm = (x_test_image / 255.0 * 255 - 128).astype(np.int8)\n",
        "\n",
        "# Initialize an array to store the predictions\n",
        "predictions = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9fwtAF3sRP"
      },
      "source": [
        "We normalize the entire test set and initialize an array to store the predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z1Clh4Kt3fuF"
      },
      "outputs": [],
      "source": [
        "# Iterate over the test data and make predictions\n",
        "for i in range(len(x_test_image_norm)):\n",
        "    test_image = np.expand_dims(x_test_image_norm[i].flatten(), axis=0)\n",
        "    \n",
        "    # Set the value for the input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
        "    \n",
        "    # Run the inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predictions.append(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1PzXSuj3uy9"
      },
      "source": [
        "We then iterate over the test set, making predictions for each image. For each image, we flatten the image, normalize it, and then expand its dimensions to match the shape of our model's input tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5wWyve_E3uL8",
        "outputId": "465afb87-ee21-43ad-81e0-ee4d544cc2dd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1400 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_labels_prediction(images,labels,idx,num=10):\n",
        "    fig=plt.gcf()\n",
        "    fig.set_size_inches(12, 14)\n",
        "    if num > 25: num=25\n",
        "    for i in range(0, num):\n",
        "        ax=plt.subplot(5, 5, i+1)\n",
        "        ax.imshow(images[idx], cmap='binary')\n",
        "        title=\"label=\" + str(labels[idx])\n",
        "        ax.set_title(title, fontsize=10)\n",
        "        ax.set_xticks([]);\n",
        "        ax.set_yticks([]);\n",
        "        idx += 1\n",
        "    plt.show()\n",
        "\n",
        "plot_images_labels_prediction(x_test_image, y_test_label, 0, 25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOHKHUMp30j8"
      },
      "source": [
        "Finally, we use a function to plot the test images along with their predicted labels. This will give us a visual representation of how well our model is performing.\n",
        "\n",
        "That's it! We have successfully trained a quantization-aware model, converted it to the TFLite format, and performed inference using the TensorFlow Lite interpreter.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywhXM1mA-a7F"
      },
      "source": [
        "# Convert your model to Orion's Cairo code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wP_kVSuEKA1U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Create an object that with all weights and biases\n",
        "params = {\n",
        "    \"input\": x_test_image[0].flatten(),\n",
        "    \"fc1_weights\": interpreter.get_tensor(1), \n",
        "    \"fc1_bias\": interpreter.get_tensor(2), \n",
        "    \"fc2_weights\": interpreter.get_tensor(4), \n",
        "    \"fc2_bias\": interpreter.get_tensor(5)\n",
        "}\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('src/generated', exist_ok=True)\n",
        "\n",
        "for param_name, param in params.items():\n",
        "    with open(os.path.join('src', 'generated', f\"{param_name}.cairo\"), \"w\") as f:\n",
        "        f.write(\n",
        "            \"use array::ArrayTrait;\\n\" +\n",
        "            \"use orion::operators::tensor::core::{TensorTrait, Tensor, ExtraParams};\\n\" +\n",
        "            \"use orion::operators::tensor::implementations::impl_tensor_i32;\\n\" +\n",
        "            \"use orion::numbers::fixed_point::core::FixedImpl;\\n\" +\n",
        "            \"use orion::numbers::signed_integer::i32::i32;\\n\\n\" +\n",
        "            \"fn {0}() -> Tensor<i32> \".format(param_name) + \"{\\n\" +\n",
        "            \"    let mut shape = ArrayTrait::<usize>::new();\\n\"\n",
        "        )\n",
        "        for dim in param.shape:\n",
        "            f.write(\"    shape.append({0});\\n\".format(dim))\n",
        "        f.write(\n",
        "            \"    let mut data = ArrayTrait::<i32>::new();\\n\"\n",
        "        )\n",
        "        for val in np.nditer(param.flatten()):\n",
        "            f.write(\"    data.append(i32 {{ mag: {0}, sign: {1} }});\\n\".format(abs(int(val)), str(val < 0).lower()))\n",
        "        f.write(\n",
        "            \"let extra = ExtraParams { fixed_point: Option::Some(FixedImpl::FP16x16(())) }; \\n\" +\n",
        "            \"    TensorTrait::new(shape.span(), data.span(), Option::Some(extra))\\n\" +\n",
        "            \"}\\n\"\n",
        "        )\n",
        "      \n",
        "with open(os.path.join('src', 'generated.cairo'), 'w') as f:\n",
        "    for param_name in params.keys():\n",
        "        f.write(f\"mod {param_name};\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nKiq8oKxklon",
        "ix3qnUgElDlB",
        "7Bu55FCqlbj4",
        "XhbweTQEmWN-",
        "zxGWitSs3MAH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
